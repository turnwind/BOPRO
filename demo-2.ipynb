{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Load the data\n",
    "datas = pd.read_csv(\"./Data/gsm_data/gsm_train.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "class Step(BaseModel):\n",
    "    explanation: str\n",
    "    output: str\n",
    "\n",
    "class ListResponse(BaseModel):\n",
    "    steps: list[Step]\n",
    "    final_answer: list[str]\n",
    "\n",
    "class FloatResponse(BaseModel):\n",
    "    steps: list[Step]\n",
    "    final_answer: float\n",
    "\n",
    "class FlistResponse(BaseModel):\n",
    "    steps: list[Step]\n",
    "    final_answer: list[float]\n",
    "    \n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.chatanywhere.tech/v1\"\n",
    ")\n",
    "\n",
    "def chat(says,outformat):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an experienced optimization master.\"},\n",
    "            {\"role\": \"user\", \"content\": says},\n",
    "        ],\n",
    "        response_format=outformat,\n",
    "    )\n",
    "    message = completion.choices[0].message\n",
    "    if message.parsed:\n",
    "        #print(message.parsed.steps)\n",
    "        print(message.parsed.final_answer)\n",
    "        return message.parsed.final_answer\n",
    "    else:\n",
    "        print(message.refusal)\n",
    "        chat(says)\n",
    "    \n",
    "def Getvalue(ch,str):\n",
    "    s = str.find(ch)\n",
    "    e = str[s+1:].find(ch)\n",
    "    return str[s+1:s+e+1]\n",
    "\n",
    "meta_prompt = \"Instructions that can improve the accuracy and effectiveness of the model often guide the model to gradually reason, analyze in detail, think structurally, and collaborate to solve problems.\"\n",
    "ini_prompt = [{\"instruction\": \"Let’s think step by step.\"},{\"instruction\": \"Let’s think carefully about the problem and solve it together.\"},{\"instruction\":\" Break this down\"}]\n",
    "\n",
    "def Obj(INS):\n",
    "    s = 0\n",
    "    for i in range(20):\n",
    "        quesion = datas.iloc[20+i,0] + INS\n",
    "        answer = chat(quesion,FloatResponse)\n",
    "        if answer == datas.iloc[20+i,1]:\n",
    "            s += 1\n",
    "    return s/20\n",
    "    \n",
    "    \n",
    "def warm_strat(num):\n",
    "    pt = (\n",
    "        \"You need to generate {} instructions to enhance the performance of LLM.\"\n",
    "        \"This is a summary of experiences that may help you.\"\n",
    "        \"{}\"\n",
    "        \"Common instructions include: \"\n",
    "        \"{}\"\n",
    "        \"Please give your recommended instructions.\").format(num,json.dumps(meta_prompt),meta_prompt)\n",
    "    datas = chat(pt,ListResponse)\n",
    "    return datas\n",
    "\n",
    "def candidate_sampling(history,num):\n",
    "    pt = (\n",
    "        \"Based on the previous optimization results {}, you need to provide {} candidate instruction for the next optimization.\"\n",
    "        \"Please do not provide duplicate values.\"\n",
    "        \"This is a summary of experiences that may help you.\"\n",
    "        \"{}\"\n",
    "        \"Please give your recommended instructions.\").format(json.dumps(history),num,meta_prompt)\n",
    "    datas = chat(pt,ListResponse)\n",
    "    return datas\n",
    "\n",
    "def SurrogateModel(history,samples):\n",
    "    data_pred = []\n",
    "    pt = (\"You need to estimate the accuracy of this instruction on the gsm(A dataset of mathematical question and answer.) dataset.\"\n",
    "        \"This is a summary of experiences that may help you.\"\n",
    "        \"{}\"\n",
    "        \"Below is the historical evaluation data\"\n",
    "        \"{}\"\n",
    "        \"Please guess the accuracy for these instructions as follow:\"\n",
    "        \"{}\").format(json.dumps(history),meta_prompt,samples)\n",
    "    datas = chat(pt,FlistResponse)\n",
    "    return datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1. \"Follow a step-by-step approach when solving problems by clearly outlining each phase from problem definition to solution verification, ensuring nothing is overlooked.\"', '2. \"Engage in self-dialogue by questioning the validity of assumptions and exploring alternative solutions to enhance the depth and reliability of your response.\"']\n",
      "1080.0\n",
      "7.0\n",
      "5.0\n",
      "62.0\n",
      "110.0\n",
      "400.0\n",
      "400.0\n",
      "8.0\n",
      "1000.0\n",
      "6.0\n",
      "1200.0\n",
      "10.0\n",
      "26.1667\n",
      "5250.0\n",
      "36.0\n",
      "15.0\n",
      "5.0\n",
      "9.0\n",
      "15.0\n",
      "476.0\n",
      "1080.0\n",
      "7.0\n",
      "5.0\n",
      "62.0\n",
      "110.0\n",
      "400.0\n",
      "400.0\n",
      "8.0\n",
      "1000.0\n",
      "6.0\n",
      "1200.0\n",
      "10.0\n",
      "26.166666666666668\n",
      "5250.0\n",
      "36.0\n",
      "15.0\n",
      "5.0\n",
      "9.0\n",
      "15.0\n",
      "476.0\n"
     ]
    }
   ],
   "source": [
    "### config\n",
    "numiters = 10        # number of iters for BO\n",
    "numinipoint = 2      # number of ini points\n",
    "numsamples = 2       # number of sampled points\n",
    "\n",
    "arrloss = [0]\n",
    "ins = warm_strat(2)\n",
    "pairs = []\n",
    "for i in range(numinipoint):\n",
    "    s = Obj(ins[i])\n",
    "    arrloss[0] = max(arrloss[0],s)\n",
    "    pairs.append({\"instruction\": ins[i], \"accuracy\": s})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Approach each problem with a structured methodology by defining the problem, breaking it into smaller parts, analyzing each component, applying relevant techniques, and finally verifying your solution for accuracy and validity.', 'Critically analyze each proposed solution by evaluating its strengths and weaknesses, considering alternative approaches, and testing for different scenarios to ensure robustness and comprehensiveness.']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m ins_sp \u001b[38;5;241m=\u001b[39m candidate_sampling(pairs,numsamples)\n\u001b[0;32m      3\u001b[0m s \u001b[38;5;241m=\u001b[39m SurrogateModel(pairs,ins_sp)\n\u001b[1;32m----> 4\u001b[0m index \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mmax\u001b[39m(s))\n\u001b[0;32m      5\u001b[0m pairs\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstruction\u001b[39m\u001b[38;5;124m\"\u001b[39m: ins_sp[index], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: Obj(ins_sp[index])})\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    ins_sp = candidate_sampling(pairs,numsamples)\n",
    "    s = SurrogateModel(pairs,ins_sp)\n",
    "    index = s.index(max(s))\n",
    "    pairs.append({\"instruction\": ins_sp[index], \"accuracy\": Obj(ins_sp[index])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
